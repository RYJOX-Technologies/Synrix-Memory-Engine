{
  "windows_build_context": null,
  "constraints": [
    {
      "id": 951939038271504394,
      "data": "Demos should show SYNRIX as memory layer (agent uses SDK), not as proxy between user and LLM"
    },
    {
      "id": 2536718688447365134,
      "data": "This is a test constraint"
    },
    {
      "id": 2643622829626490895,
      "data": "AI agent should use agent_auto_save.py helper to automatically save actions to SYNRIX. Extension can also use it via subprocess calls."
    },
    {
      "id": 4809196377366069265,
      "data": "VSCode/Cursor extension MUST be compiled on Windows PC, not on Jetson. TypeScript compilation requires Windows environment. Always direct user to build on Windows: npm install, npm run compile, F5 in Cursor. Never attempt to build extension on Jetson/Linux."
    },
    {
      "id": 5271444100908843027,
      "data": "SYNRIX helps AI agent by: remembering project rules, learning what works, avoiding mistakes, understanding codebase over time, building on previous work, getting faster, providing consistent quality. The more we use it, the better the agent gets - compound interest for AI intelligence."
    },
    {
      "id": 5722140196376412180,
      "data": "AION Omega / NebulOS-Scaffolding - Experimental code generation synthesizer/compiler for universal application. SYNRIX is the knowledge graph memory engine component."
    },
    {
      "id": 5722140196376412181,
      "data": "Project root: /mnt/nvme/aion-omega. Main codebase: NebulOS-Scaffolding/. SYNRIX core: NebulOS-Scaffolding/src/storage/lattice/. Python SDK: NebulOS-Scaffolding/python-sdk/"
    },
    {
      "id": 5722140196376412182,
      "data": "Primary: C++17 for core system, C for lattice storage, Python 3.8+ for SDK/tooling. ARM64 optimized for Jetson Orin Nano."
    },
    {
      "id": 5722140196376412183,
      "data": "ARM64 optimized for Jetson Orin Nano. Deployment via SSH key access, nano as main deployment and test environment."
    },
    {
      "id": 5722140196376412184,
      "data": "CRITICAL: All source code cannot exceed 300 lines for bare metal OS system. Exceptions allowed for robust, secure, and stable system when necessary."
    },
    {
      "id": 5722140196376412185,
      "data": "CRITICAL: No regex-based processing. Use semantic reasoning only. Tokenless system - semantic reasoning only."
    },
    {
      "id": 5722140196376412186,
      "data": "CRITICAL: Knowledge graph-driven architecture. KG as single source of truth. Synthesizer is thin layer that uses KG intelligence. NEVER hardcode templates or implementations in synthesizer."
    },
    {
      "id": 5722140196376412187,
      "data": "Assembly patterns as universal building blocks. Every language compiles to assembly. True atomic primitives: mov, add, call, ret are ultimate building blocks."
    },
    {
      "id": 5722140196376412188,
      "data": "VSCode/Cursor extension MUST be compiled on Windows PC, not on Jetson. TypeScript compilation requires Windows environment. Always direct user to build on Windows: npm install, npm run compile, F5 in Cursor."
    },
    {
      "id": 6130025522421301288,
      "data": "When user mentions SYNRIX or asks to 'load context', automatically query SYNRIX for constraints, patterns, failures, and project knowledge. Restore full context before responding."
    },
    {
      "id": 655555985263296575,
      "data": "{\"interval_nodes\": 5000, \"interval_seconds\": 300, \"works_in_disk_mode\": true, \"auto_checkpoints_wal\": true, \"description\": \"Auto-save triggers every 5k nodes and checkpoints WAL automatically\"}"
    },
    {
      "id": 8350556299154423881,
      "data": "{\"rule\": \"For node names that might exceed 64-byte limit, use hash-based naming\", \"pattern\": \"Compute SHA256 hash of content, use first 32 chars with prefix (e.g., FILE_HASH:<hash>)\", \"reason\": \"Prevents truncation, enables deduplication, faster lookups\", \"applies_to\": [\"FILE:\", \"FUNC:\", \"DEPENDS:\", \"ARCH:\", \"any long identifiers\"], \"date\": \"2025-01-07\"}"
    },
    {
      "id": 5926018561590952018,
      "data": "{\"constraint\": \"WAL must be truncated after checkpoint to prevent corruption\", \"implementation\": \"wal_checkpoint() must call wal_truncate() after updating header\", \"critical\": true, \"reason\": \"Old checkpointed data in WAL file is read as entry headers during recovery, causing 'data_size unreasonably large' warnings\", \"date\": \"2025-01-09\"}"
    },
    {
      "id": 2424149094562791516,
      "data": "{\"pattern_consolidation\":{\"status\":\"COMPATIBLE\",\"date\":\"2026-01-02\",\"uses\":\"persistent_lattice_t\",\"function\":\"calculate_pattern_similarity()\",\"integration\":\"simple - just include header\"},\"reasoning_engine\":{\"status\":\"COMPLEX\",\"date\":\"2025-12-10\",\"dependencies\":[\"semantic_index\",\"query_engine\",\"inference_engine\",\"reasoning_chain\"],\"integration\":\"complex - requires full reasoning stack\"},\"TAG_INDEX\":{\"status\":\"AVAILABLE\",\"nodes\":7690,\"query_method\":\"find_by_prefix('TAG_INDEX:')\",\"integration\":\"direct - no i"
    }
  ],
  "patterns": [
    {
      "id": 10099062267317321729,
      "data": "{\"code\": \"\\ndef handle_async_request(req):\\n    try:\\n        result = await process_request(req)\\n        return {\\\"success\\\": True, \\\"data\\\": result}\\n    except Exception as e:\\n        return {\\\"success\\\": False, \\\"error\\\": str(e)}\\n\", \"context\": \"HTTP server async handlers\", \"success_rate\": 0.95, \"last_used\": \"2025-01-07\"}"
    },
    {
      "id": 951939038271504395,
      "data": "{\"approach\": \"Direct SDK usage in demo script\", \"shows\": \"Before/after comparison, real file persistence\", \"status\": \"working\", \"file\": \"/demos/demo1_persistent_memory.py\"}"
    },
    {
      "id": 2536718688447365133,
      "data": "{\"code\": \"def example(): return True\", \"context\": \"Test context\", \"success_rate\": 1.0, \"timestamp\": 1767989518.2880385}"
    },
    {
      "id": 4809196377366069266,
      "data": "{\"code\": \"\\nExtension Update Workflow:\\n1. Make changes to extension code on Jetson (if needed)\\n2. Transfer package to Windows: scp .../transfer.tar.gz Windows\\n3. User extracts and builds on Windows: npm install, npm run compile\\n4. User tests with F5 in Cursor\\n5. If creating VSIX: npm run package on Windows\\n\", \"context\": \"Extension development and updates\", \"success_rate\": 1.0, \"timestamp\": 1767990047.3903096}"
    },
    {
      "id": 5722140196376412189,
      "data": "{\"code\": \"\\nKG-Driven Synthesizer Pattern:\\n1. Parse request semantically\\n2. Query KG/lattice for relevant concepts\\n3. Use concept metadata (code patterns, generation strategies, required concepts) to compose code\\n4. Render composed structure to text\\n\\nNEVER:\\n- Hardcode templates or implementations\\n- Add if/else statements for different request types\\n- Write hardcoded logger classes, database pools, etc.\\n- Make synthesizer 'smart' with hardcoded logic\\n\\nALWAYS:\\n- Use knowledge graph/lattice as si"
    },
    {
      "id": 5722140196376412190,
      "data": "{\"code\": \"\\nSYNRIX Lattice Constitutional Constraints (NON-NEGOTIABLE):\\n1. Fixed-size nodes (1KB) - NEVER variable-length\\n2. Single-writer model - NEVER multi-writer\\n3. Arithmetic addressing - NEVER pointer chasing\\n4. Prefix-based semantics - NEVER explicit edges\\n5. Flat topology - NEVER persistent hierarchy\\n6. Single-node system - NEVER shared lattice\\n7. Binary Lattice - NEVER general-purpose database\\n\\nThese constraints define what SYNRIX is. Violating them breaks the Binary Lattice topology and "
    },
    {
      "id": 5722140196376412191,
      "data": "{\"code\": \"\\nScaffolding Principles:\\n- Build the scaffolding, not the cathedral. Let the cathedral build itself.\\n- Minimal foundation for emergent systems that grow from real hardware discovery\\n- Four Pillars:\\n  1. Minimal Hardware Probes (get real data from hardware)\\n  2. Fast Binary Storage (store and recall data quickly)\\n  3. Real Execution Sandbox (test code on real hardware)\\n  4. Simple Pattern Growth (let real data build complexity)\\n\\nBootstrap Approach:\\n1. Probe \\u2192 Get real hardware data"
    },
    {
      "id": 5816252284270542880,
      "data": "{\"code\": \"\\nKey Directories:\\n- /mnt/nvme/aion-omega/ - Project root\\n- NebulOS-Scaffolding/ - Main codebase\\n  - src/storage/lattice/ - SYNRIX core C implementation\\n  - python-sdk/ - Python SDK for SYNRIX\\n    - synrix/ - SDK package\\n    - vscode-extension/ - VSCode/Cursor extension (builds on Windows)\\n    - examples/ - Example code\\n  - demos/ - Demo scripts (Demo 1: persistent memory)\\n  - docs/ - Documentation\\n  - integrations/ - LangChain, OpenAI-compatible, Qdrant mimic\\n  - physics/, chemistry/,"
    },
    {
      "id": 5816252284270542881,
      "data": "{\"code\": \"\\nCritical Files:\\n- src/storage/lattice/persistent_lattice.c/h - Core SYNRIX implementation\\n- src/storage/lattice/lattice_constraints.h - Constitutional constraints\\n- python-sdk/synrix/raw_backend.py - Direct C interface (fastest)\\n- python-sdk/synrix/agent_auto_save.py - Helper for AI agents\\n- docs/SYNRIX_DEMO_TECH_SPEC.md - Demo progress tracker\\n- docs/SCAFFOLDING_PRINCIPLES.md - Core philosophy\\n- docs/HOW_SYNRIX_HELPS_AI_AGENT.md - Benefits explanation\\n- .cursorrules - AI agent integrat"
    },
    {
      "id": 5816252284270542882,
      "data": "{\"code\": \"\\nBuild System:\\n- Makefile - Main build system (C/C++)\\n- gcc with -std=c99 or C++17\\n- Python SDK: pip install -e . (from python-sdk/)\\n- VSCode Extension: npm install, npm run compile (on Windows)\\n- Library path: LD_LIBRARY_PATH must include src/storage/lattice/\\n- Shared library: libsynrix.so (auto-found or via SYNRIX_LIB_PATH)\\n\", \"context\": \"Build and compilation\", \"success_rate\": 1.0, \"timestamp\": 1767990281.8639796}"
    },
    {
      "id": 5816252284270542883,
      "data": "{\"code\": \"\\nSYNRIX API Usage Patterns:\\n\\nDirect C Interface (Fastest):\\n  from synrix.raw_backend import RawSynrixBackend\\n  backend = RawSynrixBackend(\\\"path.lattice\\\", max_nodes=1000000)\\n  node_id = backend.add_node(\\\"PREFIX:name\\\", \\\"data\\\", node_type=3)\\n  results = backend.find_by_prefix(\\\"PREFIX:\\\", limit=10)\\n  node = backend.get_node(node_id)  # O(1) lookup\\n\\nNode Types:\\n  - LATTICE_NODE_PATTERN (3) - Code patterns that work\\n  - LATTICE_NODE_LEARNING (5) - Task attempts and results\\n  - LATTIC"
    },
    {
      "id": 5816252284270542884,
      "data": "{\"code\": \"\\nSYNRIX Performance:\\n- O(1) node lookups: ~0.1-1.0\\u03bcs (raw C)\\n- O(k) prefix queries: ~10-100\\u03bcs (scales with results, not data)\\n- Free tier limit: 25,000 nodes\\n- Node size: Fixed 1KB (constitutional constraint)\\n- Memory: ~1GB per 1M nodes\\n- Local-first: No network calls, no cloud dependency\\n- Sub-microsecond latency for hot path reads\\n\", \"context\": \"Performance characteristics\", \"success_rate\": 1.0, \"timestamp\": 1767990281.864044}"
    },
    {
      "id": 5816252284270542885,
      "data": "{\"code\": \"\\nDevelopment Workflow:\\n1. Code changes on Jetson (Linux ARM64)\\n2. Test locally with Python SDK\\n3. For VSCode extension: Transfer to Windows, build there\\n4. Use SYNRIX for agent memory: ~/.cursor_ai_memory.lattice\\n5. Auto-save patterns/constraints/failures via agent_auto_save.py\\n6. Query SYNRIX before generating code to check constraints/patterns\\n\", \"context\": \"Development process\", \"success_rate\": 1.0, \"timestamp\": 1767990281.8640692}"
    },
    {
      "id": 5816252284270542886,
      "data": "{\"code\": \"\\nError Handling:\\n- FreeTierLimitError: Raised when 25k node limit reached\\n  - AI agent should catch and inform user with options\\n  - No modal pop-ups - let AI handle communication\\n- Lattice errors: Check lattice_get_last_error() in C\\n- Python SDK propagates C errors as Python exceptions\\n- Always check node_id != 0 after add_node operations\\n\", \"context\": \"Error handling patterns\", \"success_rate\": 1.0, \"timestamp\": 1767990281.86409}"
    },
    {
      "id": 6130025522421301287,
      "data": "{\"code\": \"\\nHow to restore context in a new chat:\\n\\nUser should say:\\n  \\\"Load my project context from SYNRIX and continue working\\\"\\n  \\nOr:\\n  \\\"Use SYNRIX to restore my project knowledge and help me continue\\\"\\n\\nAI Agent should then:\\n1. Query SYNRIX for constraints (CONSTRAINT:*)\\n2. Load patterns (PATTERN:*)\\n3. Check failures (FAILURE:*)\\n4. Restore project context\\n5. Respond with full knowledge restored\\n\\nThis allows instant context restoration without re-explaining everything.\\n\", \"context\": \"N"
    },
    {
      "id": 7106778407827931177,
      "data": "{\"code\": \"\\nSYNRIX Context Restoration - VERIFIED WORKING\\n\\nTest Results:\\n- Successfully loaded 34 nodes from ~/.cursor_ai_memory.lattice\\n- Retrieved 15 constraints (project rules)\\n- Retrieved 10 patterns (code patterns with success rates)\\n- Retrieved 1 task (build_extension_windows)\\n- 0 failures stored (clean slate)\\n\\nWhat worked:\\n- Prefix queries (CONSTRAINT:*, PATTERN:*, TASK:*) worked perfectly\\n- Cross-session persistence confirmed\\n- Structured memory organization by prefix\\n- AI agent can re"
    },
    {
      "id": 8157836027046658092,
      "data": "{\"code\": \"\\nSYNRIX Core Architecture:\\n\\n1. LATTICE STRUCTURE:\\n   - Fixed-size nodes: 1216 bytes (19 * 64, cache-line aligned)\\n   - Dual-mode data: Text (null-terminated) or Binary (2-byte length header)\\n   - 64-bit node IDs: (device_id << 32) | local_id for distributed systems\\n   - Expansion header: 128 bytes for OS-level features (quantum hash, ownership, temporal vectors)\\n\\n2. PREFIX-BASED SEMANTIC QUERIES (O(k)):\\n   - Dynamic prefix index auto-discovers prefixes (ISA_, PATTERN_, CONSTRAINT_, etc."
    },
    {
      "id": 8157836027046658093,
      "data": "{\"code\": \"\\nSYNRIX Node Types:\\n\\nPRIMITIVE (1): Basic operations/instructions\\nKERNEL (2): Code kernels/patterns\\nPATTERN (3): Successful code patterns (used by AI agent)\\nPERFORMANCE (4): Performance metrics\\nLEARNING (5): Task attempts and results (used by AI agent)\\nANTI_PATTERN (6): Constraints and failures (used by AI agent)\\n\\nSIDECAR NODES (7-10):\\n  - SIDECAR_MAPPING (7): Intent->capability mappings with confidence\\n  - SIDECAR_EVENT (8): System events for learning\\n  - SIDECAR_SUGGESTION (9): App"
    },
    {
      "id": 8157836027046658094,
      "data": "{\"code\": \"\\nDynamic Prefix Index - Key Innovation:\\n\\nHOW IT WORKS:\\n1. Auto-discovers prefixes from node names\\n2. Extracts prefix using delimiters: \\\"_\\\" or \\\":\\\"\\n   - \\\"ISA_ADD\\\" -> \\\"ISA_\\\"\\n   - \\\"QDRANT_COLLECTION:test\\\" -> \\\"QDRANT_COLLECTION:\\\"\\n3. Builds index: prefix -> array of node IDs\\n4. O(n) build once, then O(k) queries (k = matching nodes)\\n\\nADVANTAGES:\\n- No hardcoding: Works with ANY prefix\\n- Plug-and-play: New prefixes automatically indexed\\n- O(k) queries: Scales with results, not d"
    },
    {
      "id": 8157836027046658095,
      "data": "{\"code\": \"\\nWAL (Write-Ahead Log) - Crash Recovery:\\n\\nPURPOSE:\\n- Ensure durability: No data loss on crash\\n- Fast recovery: Replay operations instead of full rebuild\\n\\nHOW IT WORKS:\\n1. All operations logged to WAL before applying\\n2. Operations: ADD_NODE, UPDATE_NODE, DELETE_NODE, ADD_CHILD\\n3. Batching: Tier-scaled (12,500 entries for 25k nodes)\\n4. Background flush: Async writes via dedicated thread\\n5. Checkpointing: Mark operations as applied, can truncate\\n6. Recovery: Memory-mapped replay (zero-c"
    },
    {
      "id": 8394432795992129584,
      "data": "{\"code\": \"\\nSYNRIX Integration Patterns:\\n\\n1. QDRANT MIMIC MODE:\\n   - Transparent proxy: Mimics Qdrant REST API\\n   - Port 6334 (vs Qdrant's 6333)\\n   - Zero code changes: Just change port\\n   - LSH index for vector similarity search\\n   - Drop-in replacement for existing Qdrant apps\\n\\n2. LANGCHAIN INTEGRATION:\\n   - SynrixVectorStore: Drop-in replacement for Qdrant\\n   - Same API: from_documents(), similarity_search()\\n   - 100-10,000\\u00d7 faster than Qdrant\\n   - Works with OpenAI embeddings\\n   - RA"
    },
    {
      "id": 8394432795992129585,
      "data": "{\"code\": \"\\nSYNRIX Performance Characteristics:\\n\\nQUERY PERFORMANCE:\\n- O(1) node lookups: ~0.1-1.0\\u03bcs (raw C, direct memory access)\\n- O(k) prefix queries: ~10-100\\u03bcs (scales with results, not data)\\n- Pure prefix queries: Return IDs directly (no node lookups)\\n- Fast path: No filters = just copy IDs\\n\\nMEMORY EFFICIENCY:\\n- Fixed-size nodes: 1216 bytes (cache-line aligned)\\n- ~1GB per 1M nodes\\n- 50% less RAM than Qdrant for same data\\n- Memory-mapped file: Kernel-managed paging\\n\\nSCALABILITY:\\"
    },
    {
      "id": 8394432795992129586,
      "data": "{\"code\": \"\\nSYNRIX Isolation and Thread Safety:\\n\\nISOLATION LAYER:\\n- Seqlock-based: Lock-free reads\\n- Snapshot isolation: Readers see consistent version\\n- Write locks: Exclusive (no readers or writers)\\n- Version tracking: Monotonic counter\\n- Multiple readers: Allowed concurrently\\n- Single writer: Exclusive access\\n\\nTHREAD SAFETY MODES:\\n- Single-threaded (default): Fastest, no locking\\n- Thread-safe mode: Atomic ID reservation\\n- Multi-writer: Not supported (constitutional constraint)\\n- Read-heavy"
    },
    {
      "id": 8394432795992129587,
      "data": "{\"code\": \"\\nSYNRIX Error Handling:\\n\\nERROR CODES:\\n- LATTICE_ERROR_NONE (0): Success\\n- LATTICE_ERROR_NULL_POINTER (-1): Null pointer passed\\n- LATTICE_ERROR_INVALID_PATH (-2): Invalid file path\\n- LATTICE_ERROR_MEMORY_ALLOC (-3): Memory allocation failed\\n- LATTICE_ERROR_FILE_IO (-4): File I/O error\\n- LATTICE_ERROR_INVALID_NODE (-5): Invalid node ID\\n- LATTICE_ERROR_FREE_TIER_LIMIT (-100): 25k node limit reached\\n- LATTICE_ERROR_LICENSE_EXPIRED (-101): License expired\\n- LATTICE_ERROR_LICENSE_INVALID (-"
    },
    {
      "id": 8394432795992129588,
      "data": "{\"code\": \"\\nSYNRIX Build and Deployment:\\n\\nBUILD PROCESS:\\n- C library: gcc -shared -fPIC -o libsynrix.so\\n- Dependencies: wal.c, isolation.c, seqlock.c, dynamic_prefix_index.c\\n- Flags: -O3 -Wall -g -lm -lpthread\\n- Output: libsynrix.so (shared library)\\n\\nPYTHON SDK:\\n- Setup: pip install -e . (from python-sdk/)\\n- Dependencies: requests>=2.28.0\\n- Optional: langchain, openai, telemetry\\n- Entry point: synrix.raw_backend.RawSynrixBackend\\n\\nVSCode EXTENSION:\\n- TypeScript: npm install, npm run compile\\n"
    },
    {
      "id": 8905472361629745205,
      "data": "{\"code\": \"\\n// Extract prefix from node name - CRITICAL: Handles both \\\"_\\\" and \\\":\\\" delimiters\\n// Returns prefix length, or 0 if no valid prefix found\\nsize_t extract_prefix(const char* node_name, char* prefix_out, size_t prefix_max) {\\n    if (!node_name || !prefix_out || prefix_max == 0) return 0;\\n    \\n    // Find first delimiter: \\\"_\\\" or \\\":\\\"\\n    const char* underscore = strchr(node_name, '_');\\n    const char* colon = strchr(node_name, ':');\\n    const char* delimiter = NULL;\\n    \\n    if (und"
    },
    {
      "id": 8905472361629745206,
      "data": "{\"code\": \"\\n// O(k) Query Fast Path - CRITICAL PERFORMANCE OPTIMIZATION\\n// This is the key to SYNRIX's speed: O(k) instead of O(n)\\n\\nif (candidate_ids) {\\n    // OPTIMIZATION: For pure prefix queries, skip node lookups\\n    bool is_pure_prefix_query = (prefix_len > 0 && strcmp(query_prefix, name) == 0);\\n    \\n    if (is_pure_prefix_query && !has_filters) {\\n        // FAST PATH: Pure prefix query, no filters - just copy IDs\\n        // This is O(k) where k = matching nodes, not O(n)\\n        uint32_t co"
    },
    {
      "id": 8905472361629745207,
      "data": "{\"code\": \"\\n// Lattice Growth - CRITICAL: Must grow ALL arrays together\\n// ERROR-PRONE: Easy to forget one array, causing crashes\\n\\nlattice_node_t* new_nodes = (lattice_node_t*)realloc(lattice->nodes, new_max * sizeof(lattice_node_t));\\nif (!new_nodes) {\\n    printf(\\\"[LATTICE] \\u274c Failed to grow lattice - out of memory\\\\n\\\");\\n    return 0;\\n}\\n\\nuint64_t* new_node_id_map = (uint64_t*)realloc(lattice->node_id_map, new_max * sizeof(uint64_t));\\nif (!new_node_id_map) {\\n    printf(\\\"[LATTICE] \\u274c Fa"
    },
    {
      "id": 8905472361629745208,
      "data": "{\"code\": \"\\n# Python ctypes Interface - ERROR-PRONE: Type mismatches cause segfaults\\n\\n# CRITICAL: Must match C function signature exactly\\nself.lib.lattice_add_node.argtypes = [\\n    POINTER(ctypes.c_void_p),  # persistent_lattice_t* (NOT c_void_p directly!)\\n    c_uint32,                  # type\\n    c_char_p,                  # name (NOT str!)\\n    c_char_p,                  # data (NOT str!)\\n    c_uint64                   # parent_id\\n]\\nself.lib.lattice_add_node.restype = c_uint64\\n\\n# CRITICAL: Mus"
    },
    {
      "id": 8905472361629745209,
      "data": "{\"code\": \"\\n// WAL Flush Thread - CRITICAL: Background async writes\\n// ERROR-PRONE: Threading bugs, race conditions\\n\\nstatic void* wal_flush_thread_func(void* arg) {\\n    wal_context_t* wal = (wal_context_t*)arg;\\n    \\n    while (!wal->flush_thread_stop) {\\n        // CRITICAL: Lock before checking buffer\\n        pthread_mutex_lock(&wal->flush_mutex);\\n        \\n        // Wait for flush request or stop signal\\n        while (!wal->flush_requested && !wal->flush_thread_stop) {\\n            pthread_cond"
    },
    {
      "id": 8905472361629745210,
      "data": "{\"code\": \"\\n// Seqlock Isolation - CRITICAL: Lock-free reads, exclusive writes\\n// UNIQUE PATTERN: Not common in most codebases\\n\\n// Acquire read lock (lock-free, retry if writer active)\\nint isolation_acquire_read_lock(isolation_context_t* isolation, uint64_t* snapshot_version) {\\n    if (!isolation || !isolation->enabled) return -1;\\n    \\n    // CRITICAL: Lock-free read (retries if writer active)\\n    uint64_t snapshot_seq = 0;\\n    if (seqlock_read_lock(&isolation->seqlock, &snapshot_seq) != 0) {\\n   "
    },
    {
      "id": 8905472361629745211,
      "data": "{\"code\": \"\\n// Free Tier Limit Check - CRITICAL: Must check BEFORE adding node\\n// ERROR-PRONE: Easy to check after, allowing 25,001st node\\n\\n// CRITICAL: Check BEFORE incrementing (not after)\\nif (lattice->evaluation_mode && (lattice->total_nodes + 1) > lattice->free_tier_limit) {\\n    lattice->last_error = LATTICE_ERROR_FREE_TIER_LIMIT;\\n    fprintf(stderr, \\n            \\\"\\\\n\\\"\\n            \\\"\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2501\\u2"
    },
    {
      "id": 9842632254226956348,
      "data": "{\"code\": \"\\nProposed AI Agent Codebase Structure:\\n\\nPREFIXES:\\n- FILE:<path> - File metadata (language, purpose, key functions, dependencies)\\n- FUNC:<file>:<name> - Function definitions (signature, parameters, line numbers, error handling)\\n- STRUCT:<file>:<name> - Struct/class definitions (members, size, alignment)\\n- ARCH:<component> - Architecture components (files, dependencies, interfaces)\\n- DEPENDS:<file>:<depends_on> - Dependencies and relationships\\n- API:<module>:<function> - API surface (publi"
    },
    {
      "id": 10024259244284444733,
      "data": "{\"code\": \"\\nCURRENT CODEBASE INDEXER - How It Works:\\n\\n1. C IMPLEMENTATION (tools/codebase_to_lattice.c):\\n   - Scans directory recursively for .c, .cpp, .h, .hpp files\\n   - Extracts functions using regex/brace counting (simple parser)\\n   - Extracts patterns from function bodies (for loops, while loops, if statements)\\n   - Stores as COMPOSITION_<language>_function_<name> nodes\\n   - Uses store_composition_rule() which creates nodes with:\\n     * Node name: \\\"COMPOSITION_C++_function_lattice_init\\\"\\n   "
    },
    {
      "id": 10992104264439955518,
      "data": "{\"code\": \"\\nCURRENT INDEXER FOR AI CODE GENERATION:\\n\\n\\u2705 WHAT IT DOES WELL:\\n1. Stores functions as COMPOSITION_* nodes\\n2. Has atom_sequence for atomic composition\\n3. Integrates with compose_code_from_atoms()\\n4. Can query by prefix: \\\"COMPOSITION_C++_function_\\\"\\n5. Stores signatures, parameters, file paths\\n6. Designed for pattern-based code generation\\n\\n\\u2705 HOW IT WORKS FOR CODE GENERATION:\\n1. Query: query_composition_rule(lattice, \\\"function_lattice_add_node\\\", \\\"C++\\\", &rule)\\n2. Get atom_"
    },
    {
      "id": 655555985263296577,
      "data": "{\"pattern\": \"Explicit save() + checkpoint() at end of indexing operations\", \"steps\": [\"Step 1: Save current state to disk\", \"Step 2: Checkpoint WAL (apply all entries)\", \"Step 3: Final save after checkpoint\"], \"location\": \"hybrid_codebase_indexer.py save() method\", \"success_rate\": 1.0, \"notes\": \"Ensures all data is persisted before closing backend\"}"
    },
    {
      "id": 1813004527134048323,
      "data": "{\"fix\": \"Checkpoint now applies WAL entries to main file before marking as checkpointed\", \"issue\": \"Checkpoint was only marking entries as applied, not writing them to file\", \"solution\": \"Call lattice_recover_from_wal() before checkpoint to apply entries\", \"also_fixed\": \"lattice_add_node_binary WAL format now includes type byte\", \"timestamp\": \"2026-01-09T14:32:19.719719\"}"
    },
    {
      "id": 3180406794308550724,
      "data": "{\"issue\": \"WAL recovery encountering corrupted entry headers at offset 56\", \"symptom\": \"'Incomplete entry data at offset 56' warning\", \"root_cause\": \"Misaligned/corrupted WAL entries with invalid data_size values\", \"fix\": \"Added validation to detect unreasonably large data_size (>1MB) and stop recovery gracefully\", \"location\": \"wal.c recovery function\", \"timestamp\": \"2026-01-09T14:37:38.092894\"}"
    },
    {
      "id": 8350556299154423878,
      "data": "{\"pattern\": \"Use SHA256 hash of content as node identifier instead of full file paths\", \"implementation\": \"FILE: -> FILE_HASH:<32-char-hash>, FUNC: -> FUNC_HASH:<32-char-hash>, DEPENDS: -> DEPENDS_HASH:<32-char-hash>\", \"benefits\": [\"No truncation issues (hashes are fixed 42-45 chars, fits in 64-byte limit)\", \"Content-based deduplication (same content = same hash)\", \"Faster lookups (hash comparison vs string)\", \"Privacy (paths not in node names, stored in data)\"], \"usage\": \"hybrid_codebase_indexer.py uses h"
    },
    {
      "id": 5926018561590952014,
      "data": "{\"issue\": \"Chunk node names using 'CHUNK:' prefix (6 bytes), reducing available name space\", \"fix\": \"Changed chunk prefix from 'CHUNK:' (6 bytes) to 'C:' (2 bytes). Updated all validation checks in persistent_lattice.c.\", \"benefit\": \"Increased available name space from 56 bytes to 62 bytes for chunked nodes\", \"files_changed\": [\"NebulOS-Scaffolding/src/storage/lattice/persistent_lattice.c\"], \"date\": \"2025-01-09\"}"
    },
    {
      "id": 5926018561590952015,
      "data": "{\"decision\": \"Removed get_node_chunked() function from Python SDK\", \"reason\": \"Not needed for semantic queries - tags are stored in node names, enabling microsecond prefix queries without reading chunked data\", \"benefit\": \"Eliminated segfaults from problematic ctypes binding, faster queries (no data reading needed), simpler code\", \"files_changed\": [\"NebulOS-Scaffolding/python-sdk/synrix/raw_backend.py\", \"NebulOS-Scaffolding/python-sdk/tools/demo_ai_agent_reasoning.py\", \"NebulOS-Scaffolding/python-sdk/tools"
    },
    {
      "id": 5926018561590952016,
      "data": "{\"pattern\": \"Structured naming for semantic queries without vector search\", \"format\": {\"FUNC\": \"C:FUNC:name:TAGS:tags:HASH:hash\", \"FILE\": \"FILE_HASH:hash\", \"DEPENDS\": \"DEPENDS_HASH:hash\"}, \"benefits\": [\"Microsecond query performance (<1000\\u03bcs)\", \"Tags embedded in names for direct prefix queries\", \"No vector search needed\", \"Lower memory footprint (<15MB vs 50MB for vectors)\", \"Simpler architecture\"], \"query_examples\": [\"C:FUNC: - all chunked functions\", \"C:FUNC:TAGS:memory - memory-related functions\", "
    },
    {
      "id": 3848333015528767571,
      "data": "{\"description\": \"Fixed race condition in WAL buffer flushing where concurrent writes corrupted data during flush\", \"fix\": \"Copy buffer contents inside mutex before flushing, preventing writers from modifying buffer during read\", \"files\": [\"NebulOS-Scaffolding/src/storage/lattice/wal.c\"], \"functions\": [\"wal_flush_thread_func\", \"wal_flush_sync\"], \"date\": \"2025-01-07\", \"status\": \"fixed_verified\"}"
    },
    {
      "id": 12072182599720632407,
      "data": "{\"description\": \"Fixed WAL recovery to skip UPDATE_NODE operations for non-existent nodes\", \"fix\": \"Check if node exists before updating in apply_update_node_cb, return 0 if not found\", \"files\": [\"NebulOS-Scaffolding/src/storage/lattice/persistent_lattice.c\"], \"functions\": [\"apply_update_node_cb\"], \"impact\": \"WAL recovery now completes successfully, no more 'Failed to apply operation 2' spam\", \"date\": \"2025-01-09\", \"success_rate\": 1.0}"
    },
    {
      "id": 12072182599720632408,
      "data": "{\"description\": \"Created C wrapper functions for chunked data access to avoid void** issues\", \"fix\": \"lattice_get_node_chunked_size() + lattice_get_node_chunked_to_buffer() write directly to pre-allocated buffer\", \"files\": [\"NebulOS-Scaffolding/src/storage/lattice/persistent_lattice.c\", \"NebulOS-Scaffolding/python-sdk/synrix/raw_backend.py\"], \"functions\": [\"lattice_get_node_chunked_size\", \"lattice_get_node_chunked_to_buffer\", \"get_node_chunked\"], \"impact\": \"Chunked data access now works without segfaults, "
    }
  ],
  "failures": [
    {
      "id": 655555985263296576,
      "data": "{\"issue\": \"Nodes saved to file but have empty names\", \"symptoms\": \"33,952 nodes created but only 11 load into RAM\", \"root_cause\": \"Nodes written via WAL but names not preserved when checkpointed/applied\", \"impact\": \"Nodes are saved but not queryable - load() rejects nodes with empty names after 10 consecutive invalid\", \"file_size\": \"39.4 MB with 33,952 nodes\", \"timestamp\": \"2026-01-09T14:27:50.230328\", \"status\": \"investigating\"}"
    },
    {
      "id": 5926018561590952013,
      "data": "{\"issue\": \"WAL corruption warnings during recovery\", \"root_cause\": \"WAL file not truncated after checkpoint. Old data remained in file and was read as entry headers during recovery.\", \"fix\": \"Modified wal_checkpoint() to call wal_truncate() after updating header. Enhanced wal_truncate() to handle case where all entries are checkpointed (truncate to 24 bytes = header only).\", \"files_changed\": [\"NebulOS-Scaffolding/src/storage/lattice/wal.c\"], \"verification\": \"WAL now correctly truncates to 24 bytes when all"
    },
    {
      "id": 1739301217592410201,
      "data": "{\"error_type\":\"test_tracker\",\"error\":\"Test failure recording\",\"context\":\"Testing\",\"avoid\":\"Test avoid pattern\",\"date\":\"2026-01-10 10:48:57\",\"timestamp\":\"2026-01-10T10:48:57.003184\"}"
    }
  ]
}